{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNTKmZmYHMNHGh7jdnXWBbr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EehgFWDaEIa7"
      },
      "outputs": [],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your video file"
      ],
      "metadata": {
        "id": "XwsTudwtEQUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "jKCx-LC7JAkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Load models\n",
        "vehicle_model = YOLO(\"yolov8s.pt\")\n",
        "plate_model = YOLO(\"/content/drive/MyDrive/Vehicle-NumberPlateDetection /Number Plate/best.pt\")\n",
        "\n",
        "# Prepare output directory\n",
        "save_folder = \"/content/cropped_plates\"\n",
        "if os.path.exists(save_folder):\n",
        "    shutil.rmtree(save_folder)\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "# Setup video input and output\n",
        "cap = cv2.VideoCapture(\"/content/test1.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"/content/output_video.mp4\", fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "vehicle_classes = [2, 3, 5, 7]\n",
        "coco_classes = {2: \"Car\", 3: \"Motorcycle\", 5: \"Bus\", 7: \"Truck\"}\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Optionally work with full-res (already used as-is)\n",
        "    full_frame = frame.copy()\n",
        "    vehicle_boxes = []\n",
        "\n",
        "    # Detect and track vehicles\n",
        "    result_vehicles = vehicle_model.track(full_frame, persist=True, conf=0.3)\n",
        "    if result_vehicles[0].boxes.id is not None:\n",
        "        for box in result_vehicles[0].boxes:\n",
        "            class_id = int(box.cls[0])\n",
        "            if class_id in vehicle_classes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                vehicle_id = int(box.id[0])\n",
        "                label = coco_classes.get(class_id, \"Vehicle\")\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                cv2.putText(frame, f\"{label} ID {vehicle_id}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "                vehicle_boxes.append({\n",
        "                    \"id\": vehicle_id,\n",
        "                    \"box\": (x1, y1, x2, y2)\n",
        "                })\n",
        "\n",
        "    # Detect number plates\n",
        "    result_plates = plate_model(full_frame)\n",
        "    for box in result_plates[0].boxes.xyxy:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        assigned_id = \"Unknown\"\n",
        "\n",
        "        for v in vehicle_boxes:\n",
        "            vx1, vy1, vx2, vy2 = v[\"box\"]\n",
        "            if vx1 <= cx <= vx2 and vy1 <= cy <= vy2:\n",
        "                assigned_id = v[\"id\"]\n",
        "                break\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Plate of ID {assigned_id}\", (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "        # Crop, upscale & save as PNG\n",
        "        plate_crop = full_frame[y1:y2, x1:x2]\n",
        "        if assigned_id != \"Unknown\" and plate_crop.size > 0:\n",
        "            plate_crop = cv2.resize(plate_crop, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
        "            filename = f\"{save_folder}/plate_vid{assigned_id}_frame{frame_count:05d}.png\"\n",
        "            cv2.imwrite(filename, plate_crop)\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"âœ… Done! Cleared folder and saved cropped plates to: {save_folder}\")"
      ],
      "metadata": {
        "id": "EBR0WfbvESi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "q15eVhtsthCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image, ImageEnhance\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from difflib import SequenceMatcher\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load TrOCR\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-printed\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-printed\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Load Zero-DCE\n",
        "zero_dce_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Zero-DCE-data/zero_dce_model.keras\", compile=False)\n",
        "\n",
        "# Constants\n",
        "plate_dir = \"/content/cropped_plates\"\n",
        "preprocessed_dir = \"/content/preprocessed_plates\"\n",
        "BRIGHTNESS_THRESHOLD = 100  # You can tune this\n",
        "\n",
        "# Clear and recreate preprocessing folder\n",
        "if os.path.exists(preprocessed_dir):\n",
        "    shutil.rmtree(preprocessed_dir)\n",
        "os.makedirs(preprocessed_dir, exist_ok=True)\n",
        "\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(plate_dir)\n",
        "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "])\n",
        "\n",
        "pattern1 = re.compile(r\"^[A-Z]{2}-\\d{4}$\")     # AB-1234\n",
        "pattern2 = re.compile(r\"^[A-Z]{3}\\d{4}$\")      # ABC1234\n",
        "\n",
        "# Helper: check brightness\n",
        "def compute_brightness(pil_img):\n",
        "    gray = pil_img.convert('L')\n",
        "    np_img = np.array(gray)\n",
        "    return np.mean(np_img)\n",
        "\n",
        "# Helper: apply zero-dce enhancement\n",
        "def enhance_with_zero_dce(pil_img):\n",
        "    img = pil_img.resize((224, 224))  # Resize for model\n",
        "    img_np = np.array(img) / 255.0\n",
        "    input_tensor = tf.convert_to_tensor(img_np, dtype=tf.float32)\n",
        "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "    enhanced_img = zero_dce_model(input_tensor)[0]\n",
        "    enhanced_img = tf.clip_by_value(enhanced_img, 0, 1)\n",
        "    enhanced_img = (enhanced_img[0].numpy() * 255).astype(np.uint8)\n",
        "    return Image.fromarray(enhanced_img)\n",
        "\n",
        "# Preprocess image (after optional DCE)\n",
        "def preprocess_plate(image, save_path=None):\n",
        "    width, height = image.size\n",
        "    image = image.crop((int(width * 0.2), 0, width, height))  # Crop province\n",
        "\n",
        "    # Upscale\n",
        "    upscale_size = (int(image.width * 2), int(image.height * 2))\n",
        "    image = image.resize(upscale_size, resample=Image.BICUBIC)\n",
        "\n",
        "    # Convert to grayscale â†’ histogram equalize â†’ blur â†’ sharpen\n",
        "    gray = np.array(image.convert(\"L\"))\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "    blurred = cv2.GaussianBlur(equalized, (3, 3), 0)\n",
        "\n",
        "    sharp = ImageEnhance.Sharpness(Image.fromarray(blurred)).enhance(2.0)\n",
        "    contrast = ImageEnhance.Contrast(sharp).enhance(1.5)\n",
        "\n",
        "    processed_image = contrast.convert(\"RGB\")\n",
        "\n",
        "    if save_path is not None:\n",
        "        processed_image.save(save_path)\n",
        "\n",
        "    return processed_image\n",
        "\n",
        "vehicle_reads = defaultdict(list)\n",
        "\n",
        "for img_file in image_files:\n",
        "    match = re.match(r\"plate_vid(\\d+)_frame\\d+\\.png\", img_file)\n",
        "    if not match:\n",
        "        continue\n",
        "    vehicle_id = match.group(1)\n",
        "    img_path = os.path.join(plate_dir, img_file)\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    brightness = compute_brightness(image)\n",
        "    if brightness < BRIGHTNESS_THRESHOLD:\n",
        "        image = enhance_with_zero_dce(image)\n",
        "\n",
        "    save_path = os.path.join(preprocessed_dir, img_file)\n",
        "    processed = preprocess_plate(image, save_path=save_path)\n",
        "\n",
        "    pixel_values = processor(images=processed, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    cleaned = generated_text.replace(\" \", \"\").upper()\n",
        "\n",
        "    if pattern1.match(cleaned) or pattern2.match(cleaned):\n",
        "        print(f\"{img_file} â†’ {cleaned} âœ… (valid)\")\n",
        "        vehicle_reads[vehicle_id].append((img_file, cleaned))\n",
        "    else:\n",
        "        print(f\"{img_file} â†’ {cleaned} âŒ (invalid)\")\n",
        "\n",
        "# Group and save\n",
        "def group_similar(strings, threshold=0.75):\n",
        "    groups = []\n",
        "    for s in strings:\n",
        "        placed = False\n",
        "        for g in groups:\n",
        "            if SequenceMatcher(None, s, g[0]).ratio() >= threshold:\n",
        "                g.append(s)\n",
        "                placed = True\n",
        "                break\n",
        "        if not placed:\n",
        "            groups.append([s])\n",
        "    return groups\n",
        "\n",
        "final_rows = []\n",
        "\n",
        "for vehicle_id, entries in vehicle_reads.items():\n",
        "    if not entries:\n",
        "        continue\n",
        "\n",
        "    all_valid_texts = [text for _, text in entries]\n",
        "    groups = group_similar(all_valid_texts, threshold=0.75)\n",
        "\n",
        "    best_group = max(groups, key=lambda g: len(g))\n",
        "    best_plate = Counter(best_group).most_common(1)[0][0]\n",
        "\n",
        "    last_frame = sorted([img for img, text in entries if text in best_group])[-1]\n",
        "\n",
        "    print(f\"Vehicle {vehicle_id} â†’ selected plate: {best_plate} (from {last_frame})\")\n",
        "    final_rows.append({\"image\": last_frame, \"predicted_plate\": best_plate})\n",
        "\n",
        "df = pd.DataFrame(final_rows)\n",
        "df.to_csv(\"/content/recognized_plates_grouped.csv\", index=False)\n",
        "print(\"âœ… Final grouped results saved to recognized_plates_grouped.csv\")\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ðŸ“Š Evaluation Metrics (Without Ground Truth)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# 1. Format Validity Rate\n",
        "valid_total = sum(1 for entries in vehicle_reads.values() for _, text in entries if pattern1.match(text) or pattern2.match(text))\n",
        "total_attempts = sum(len(entries) for entries in vehicle_reads.values())\n",
        "valid_rate = valid_total / total_attempts if total_attempts > 0 else 0\n",
        "print(f\"\\nðŸ“Š Format Validity Rate: {valid_rate:.2%} ({valid_total}/{total_attempts})\")\n",
        "\n",
        "# 2. Average Consistency per Vehicle\n",
        "consistent_total = 0\n",
        "for vehicle_id, entries in vehicle_reads.items():\n",
        "    texts = [text for _, text in entries]\n",
        "    if texts:\n",
        "        most_common = Counter(texts).most_common(1)[0][1]\n",
        "        consistency = most_common / len(texts)\n",
        "        consistent_total += consistency\n",
        "avg_consistency = consistent_total / len(vehicle_reads) if vehicle_reads else 0\n",
        "print(f\"ðŸ“Š Average Consistency per Vehicle: {avg_consistency:.2%}\")\n",
        "\n",
        "# 3. Heuristic Quality Checks\n",
        "invalid_chars = 0\n",
        "short_or_long = 0\n",
        "for vehicle_id, entries in vehicle_reads.items():\n",
        "    for _, text in entries:\n",
        "        if re.search(r\"[^A-Z0-9\\-]\", text):  # unexpected characters\n",
        "            invalid_chars += 1\n",
        "        if len(text) < 6 or len(text) > 8:\n",
        "            short_or_long += 1\n",
        "\n",
        "print(f\"ðŸ“Š Heuristic Alert: {invalid_chars} outputs contain invalid characters.\")\n",
        "print(f\"ðŸ“Š Heuristic Alert: {short_or_long} outputs have unusual lengths.\")\n"
      ],
      "metadata": {
        "id": "YHh4UlbGNWLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Load models\n",
        "vehicle_model = YOLO(\"yolov8s.pt\")\n",
        "plate_model = YOLO(\"/content/drive/MyDrive/Vehicle-NumberPlateDetection /Number Plate/best.pt\")\n",
        "\n",
        "# Prepare output directory\n",
        "save_folder = \"/content/cropped_plates\"\n",
        "if os.path.exists(save_folder):\n",
        "    shutil.rmtree(save_folder)\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "# Setup video input and output\n",
        "cap = cv2.VideoCapture(\"/content/test1.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"/content/output_video.mp4\", fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "vehicle_classes = [2, 3, 5, 7]\n",
        "coco_classes = {2: \"Car\", 3: \"Motorcycle\", 5: \"Bus\", 7: \"Truck\"}\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "# Placeholder lists to collect predictions and ground truths for evaluation\n",
        "predicted_plates = []  # Each element: {\"frame\": int, \"id\": int, \"box\": (x1,y1,x2,y2)}\n",
        "ground_truth_plates = []  # You must fill this with your actual GT data\n",
        "\n",
        "def iou(boxA, boxB):\n",
        "    # Compute Intersection over Union of two boxes\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "\n",
        "    iou_val = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou_val\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    full_frame = frame.copy()\n",
        "    vehicle_boxes = []\n",
        "\n",
        "    result_vehicles = vehicle_model.track(full_frame, persist=True, conf=0.3)\n",
        "    if result_vehicles[0].boxes.id is not None:\n",
        "        for box in result_vehicles[0].boxes:\n",
        "            class_id = int(box.cls[0])\n",
        "            if class_id in vehicle_classes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                vehicle_id = int(box.id[0])\n",
        "                label = coco_classes.get(class_id, \"Vehicle\")\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                cv2.putText(frame, f\"{label} ID {vehicle_id}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "                vehicle_boxes.append({\n",
        "                    \"id\": vehicle_id,\n",
        "                    \"box\": (x1, y1, x2, y2)\n",
        "                })\n",
        "\n",
        "    result_plates = plate_model(full_frame)\n",
        "    for box in result_plates[0].boxes.xyxy:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        assigned_id = \"Unknown\"\n",
        "\n",
        "        for v in vehicle_boxes:\n",
        "            vx1, vy1, vx2, vy2 = v[\"box\"]\n",
        "            if vx1 <= cx <= vx2 and vy1 <= cy <= vy2:\n",
        "                assigned_id = v[\"id\"]\n",
        "                break\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Plate of ID {assigned_id}\", (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "        # Crop, upscale & save as PNG\n",
        "        plate_crop = full_frame[y1:y2, x1:x2]\n",
        "        if assigned_id != \"Unknown\" and plate_crop.size > 0:\n",
        "            plate_crop = cv2.resize(plate_crop, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
        "            filename = f\"{save_folder}/plate_vid{assigned_id}_frame{frame_count:05d}.png\"\n",
        "            cv2.imwrite(filename, plate_crop)\n",
        "\n",
        "        # Save prediction for evaluation\n",
        "        predicted_plates.append({\n",
        "            \"frame\": frame_count,\n",
        "            \"id\": assigned_id,\n",
        "            \"box\": (x1, y1, x2, y2)\n",
        "        })\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"âœ… Done! Cleared folder and saved cropped plates to: {save_folder}\")\n",
        "\n",
        "# ----------------\n",
        "# Evaluation metrics calculation\n",
        "# ----------------\n",
        "\n",
        "# For simplicity, let's compute counts for TP, FP, FN for plate detection per frame and vehicle id.\n",
        "\n",
        "# Parameters\n",
        "IOU_THRESHOLD = 0.5\n",
        "\n",
        "# Convert ground_truth_plates and predicted_plates into dicts keyed by (frame, id) for quick access\n",
        "gt_dict = {}\n",
        "for gt in ground_truth_plates:\n",
        "    gt_dict.setdefault((gt[\"frame\"], gt[\"id\"]), []).append(gt[\"box\"])\n",
        "\n",
        "pred_dict = {}\n",
        "for pred in predicted_plates:\n",
        "    pred_dict.setdefault((pred[\"frame\"], pred[\"id\"]), []).append(pred[\"box\"])\n",
        "\n",
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "for key in set(list(gt_dict.keys()) + list(pred_dict.keys())):\n",
        "    gt_boxes = gt_dict.get(key, [])\n",
        "    pred_boxes = pred_dict.get(key, [])\n",
        "\n",
        "    matched_gt = set()\n",
        "    matched_pred = set()\n",
        "\n",
        "    for i, pbox in enumerate(pred_boxes):\n",
        "        matched = False\n",
        "        for j, gtbox in enumerate(gt_boxes):\n",
        "            if j in matched_gt:\n",
        "                continue\n",
        "            if iou(pbox, gtbox) >= IOU_THRESHOLD:\n",
        "                TP += 1\n",
        "                matched_gt.add(j)\n",
        "                matched_pred.add(i)\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            FP += 1\n",
        "    # Any ground truths not matched count as FN\n",
        "    FN += (len(gt_boxes) - len(matched_gt))\n",
        "\n",
        "# Avoid division by zero\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "accuracy = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "print(f\"Evaluation metrics:\\nAccuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "H1N1pRSNt6s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRCgRbYaza6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}